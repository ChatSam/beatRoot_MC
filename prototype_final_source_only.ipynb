{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 08:27:04.483992: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pylab as plt\n",
    "import librosa \n",
    "import numpy as np\n",
    "from glob import glob \n",
    "import librosa.display \n",
    "import IPython.display as ipd\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "from PIL import Image\n",
    "from scipy.spatial.distance import cosine\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def song_to_spectrogram(song_path,length_sec=30,save_image=True, save_name=\"spectrogram.png\"):\n",
    "\n",
    "    y, sr = librosa.load(song_path)\n",
    "    y=y[:sr*length_sec  ]\n",
    "\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr,hop_length=512)\n",
    "    S_DB = librosa.amplitude_to_db(S, ref=np.max)\n",
    "\n",
    "    # Desired width in pixels\n",
    "    desired_width = 336\n",
    "\n",
    "    # Calculate the DPI needed to achieve the desired width\n",
    "    dpi = int(desired_width / plt.figure(figsize=(desired_width / 80, 4)).get_figwidth())\n",
    "    #plt.clf()\n",
    "\n",
    "    width=desired_width / dpi\n",
    "    fig=plt.figure(figsize=(width, width/3*2))\n",
    "    librosa.display.specshow(S_DB, sr=sr,hop_length=512,\n",
    "                             x_axis='time', y_axis='mel')\n",
    "    plt.gca().set_axis_off()\n",
    "    #plt.colorbar()\n",
    "    #plt.savefig(\"spectrogram.png\", bbox_inches='tight', pad_inches=0, transparent=False)\n",
    "    #plt.title(\"Mel spectrogram\", fontsize=20)\n",
    "    #plt.show()\n",
    "    canvas = FigureCanvasAgg(fig)\n",
    "    canvas.draw()\n",
    "    image_array = np.frombuffer(canvas.tostring_rgb(), dtype='uint8')\n",
    "    image_array = image_array.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    image = Image.fromarray(image_array)\n",
    "\n",
    "    # Define the new size\n",
    "    #new_size = (432, 288)  # Change this to your desired dimensions\n",
    "    new_size = (129, 128)\n",
    "    \n",
    "    # Resize the image\n",
    "    resized_image = image.resize(new_size, Image.LANCZOS)\n",
    "    resized_image_data = np.array(resized_image)[:,:,:3]\n",
    "    resized_image_data  = np.mean(resized_image_data, axis=2)\n",
    "    #resized_image.show()  # Opens the image using the default viewer\n",
    "\n",
    "    plt.close(fig)\n",
    "    \n",
    "    if save_image:\n",
    "        resized_image.save(save_name)\n",
    "        print(\"spectrogram saved at \"+save_name)\n",
    "\n",
    "    return resized_image_data\n",
    "\n",
    "def create_spectrograms_for_dataset(dataset_dir, save_dir):\n",
    "    songs = glob(dataset_dir + '*.wav')\n",
    "\n",
    "    for s in songs:\n",
    "        track_id = Path(s).stem.split(\"__\")[1]\n",
    "        save_path = save_dir+track_id+\".png\"\n",
    "        song_to_spectrogram(s,length_sec=30,save_image=True, save_name=save_path)\n",
    "        \n",
    "\n",
    "#dataset_dir = \"Datasets/final_playlist/\" \n",
    "#save_dir = \"Datasets/final_spectrograms/\"\n",
    "#create_spectrograms_for_dataset(dataset_dir, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 08:48:03.205821: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "base_cnn_model = load_model('/Users/chatsam/Chatura/Umass/HackUmass/CNN/Music-Genre-Classification-GTZAN/Music Genre Classification/models/custom_cnn_2d_78.h5')\n",
    "final_dense_layer_output = base_cnn_model.get_layer('dense').output\n",
    "embedding_model = Model(inputs=base_cnn_model.input, outputs=final_dense_layer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def embed_distance_cosine_sim (embed1, embed2):\n",
    "    cosine_sim = 1 - cosine(embed1.flatten(), embed2.flatten()) \n",
    "    return cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_distance_top_k(embedding_model, spectrogram_path, reference_song_path, top_k):\n",
    "#     def embed_distance_cosine_sim (embed1, embed2):\n",
    "#         cosine_sim = 1 - cosine(embed1.flatten(), embed2.flatten()) \n",
    "#         return cosine_sim\n",
    "\n",
    "#     embeddings_list = list()\n",
    "#     spectrogram_path = 'Datasets/final_spectrograms/'\n",
    "#     image_list = glob(spectrogram_path+\"*.png\")\n",
    "#     track_ids = [Path(x).stem for x in image_list]\n",
    "\n",
    "#     reference_spec = song_to_spectrogram(reference_song_path,length_sec=30,save_image=False)\n",
    "#     reference_embed = embedding_model.predict(reference_spec.reshape(-1, 128, 129,1))\n",
    "\n",
    "#     for img_path in image_list:\n",
    "#         spec = np.array(Image.open(img_path))\n",
    "#         embeds = embedding_model.predict(spec.reshape(-1, 128, 129,1))\n",
    "#         cosine_sim_score = embed_distance_cosine_sim(reference_embed, embeds)\n",
    "#         embeddings_list.append(cosine_sim_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import subprocess\n",
    "\n",
    "\n",
    "def precompute_embeddings(embedding_model, spectrogram_path):\n",
    "    embeddings_list = []\n",
    "    track_ids = []\n",
    "\n",
    "    # Process all spectrogram images\n",
    "    image_list = glob(spectrogram_path + \"*.png\")\n",
    "    for img_path in image_list:\n",
    "        spec = np.array(Image.open(img_path))\n",
    "        embeds = embedding_model.predict(spec.reshape(-1, 128, 129, 1)).flatten()\n",
    "        embeddings_list.append(embeds)\n",
    "        track_ids.append(Path(img_path).stem)\n",
    "\n",
    "    # Normalize embeddings\n",
    "    normalized_embeddings = normalize(np.array(embeddings_list))\n",
    "\n",
    "    return normalized_embeddings, track_ids\n",
    "\n",
    "def find_top_k_similar_songs(embedding_model, reference_song_path, normalized_embeddings, track_ids, top_k):\n",
    "    # Process reference song\n",
    "    reference_spec = song_to_spectrogram(reference_song_path,length_sec=30,save_image=False)\n",
    "    reference_embed = embedding_model.predict(reference_spec.reshape(-1, 128, 129, 1)).flatten()\n",
    "\n",
    "    # Normalize reference embedding\n",
    "    normalized_reference_embed = normalize(reference_embed.reshape(1, -1))\n",
    "\n",
    "    # Calculate cosine similarity scores\n",
    "    similarity_scores = np.dot(normalized_embeddings, normalized_reference_embed.T).flatten()\n",
    "\n",
    "    # Get top K similar tracks (excluding the reference track itself)\n",
    "    top_indices = np.argsort(similarity_scores)[-top_k - 1:][::-1]\n",
    "    top_similar_tracks = [(track_ids[i], similarity_scores[i]) for i in top_indices if track_ids[i] != Path(reference_song_path).stem]\n",
    "\n",
    "    return top_similar_tracks[:top_k]\n",
    "\n",
    "\n",
    "def download_spotify_track(url, output_dir):\n",
    "    try:\n",
    "        # Command split into parts\n",
    "        command = ['spotify_dl', '-l', url, '-o', output_dir]\n",
    "        \n",
    "        # Run the command\n",
    "        result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "        # Check for errors\n",
    "        if result.returncode != 0:\n",
    "            return f\"Error: {result.stderr}\"\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "    save_path = glob(output_dir+\"*/*.wav\")[0]\n",
    "\n",
    "    return save_path\n",
    "\n",
    "\n",
    "def initialize_model(spec_path='Datasets/final_spectrograms/'):\n",
    "    # Example usage\n",
    "    normalized_embeddings, track_ids = precompute_embeddings(embedding_model, spec_path)\n",
    "    return normalized_embeddings, track_ids\n",
    "\n",
    "\n",
    "def get_scores(ref_track_id, normalized_embeddings, track_ids, top_k=3):\n",
    "    reference_song_path = 'path_to_reference_song.png'\n",
    "    ref_url = 'https://open.spotify.com/track/'+ ref_track_id\n",
    "    reference_song_path = download_spotify_track(ref_url, output_dir='./'+ref_track_id)\n",
    "\n",
    "    top_k_tracks = find_top_k_similar_songs(embedding_model, reference_song_path, normalized_embeddings, track_ids, top_k)\n",
    "    return top_k_tracks\n",
    "\n",
    "\n",
    "spec_path = 'Datasets/final_spectrograms/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrogram saved at Datasets/final_spectrograms/6ebcJ4agTdGzmfpXHnedY6.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 420x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = glob('/Users/chatsam/Chatura/Umass/HackUmass/Bkup_test_data/*/*.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/chatsam/Chatura/Umass/HackUmass/Bkup_test_data/test/0_ref_piano.mp3',\n",
       " '/Users/chatsam/Chatura/Umass/HackUmass/Bkup_test_data/test/1_ref_song_malone.mp3']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
